{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996476d-38f7-4c41-9edf-cec9936ed03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63a263-6b84-4a8f-baed-a89372330e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064af9d-7424-4d82-b81c-0a4518cd72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(\n",
    "    bootstrap_servers='kafka-cluster-kafka-bootstrap.kafka-cluster-project.svc.cluster.local:9092',\n",
    "    auto_offset_reset='latest',\n",
    "    value_deserializer=lambda m: json.loads(m.decode('ascii','ignore'))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f5027-7a12-49ce-b49e-4e5479e59f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import JSONEncoder\n",
    "import numpy\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, numpy.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9822436f-bf72-433d-8213-55794f22c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers='kafka-cluster-kafka-bootstrap.kafka-cluster-project.svc.cluster.local:9092',value_serializer=lambda v: json.dumps(v, cls=NumpyArrayEncoder).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00cfd1-fe03-4a99-b388-8d3a8d26e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.subscribe('lad-jaeger-spans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419444f-ad85-4302-bd9c-b24feee87f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "# open the file in the read mode\n",
    "f = open('final_log_data.csv', 'r')\n",
    "\n",
    "# create the csv reader\n",
    "csv_reader = csv.reader(f)\n",
    "next(csv_reader, None)  # skip the headers\n",
    "\n",
    "num_of_comments = 1000\n",
    "i = 1\n",
    "comments = []\n",
    "durations = []\n",
    "labels = []\n",
    "for row in csv_reader:\n",
    "    comment = row[2]\n",
    "    duration = row[0]\n",
    "    label = row[3]\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    comment = re.sub(r'\\s+', ' ', comment, flags=re.I)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    comment = comment.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    comment = comment.split()\n",
    "    comment = [stemmer.lemmatize(word) for word in comment]\n",
    "    comment = ' '.join(comment)\n",
    "    \n",
    "    comments.append(comment)\n",
    "    durations.append(duration)\n",
    "    labels.append(label)\n",
    "\n",
    "    i = i + 1\n",
    "    if i > num_of_comments:\n",
    "        break\n",
    "\n",
    "f.close()\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=1000, stop_words=stopwords.words('english'))\n",
    "tfidfconverter = tfidfconverter.fit(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f057ca8-2f07-4583-abf4-cf8a0b574e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "\n",
    "for message in consumer:\n",
    "    # message value and key are raw bytes -- decode if necessary!\n",
    "    # e.g., for unicode: `message.value.decode('utf-8')`\n",
    "    # print (\"%s:%d:%d: key=%s value=%s\" % (message.topic, message.partition, message.offset, message.key, message.value))\n",
    "    \n",
    "    if message.value['process']['serviceName'] == 'frontend':\n",
    "        \n",
    "        http_method = re.findall(r\"{'key': 'http\\.method', 'vStr': '(.+?)'}\",str(message.value))\n",
    "        http_target = re.findall(r\"{'key': 'http\\.target', 'vStr': '(.+?)'}\",str(message.value))\n",
    "        http_status_code = re.findall(r\"{'key': 'http\\.status_code', 'vType': '.*?', 'vInt64': '(\\d+)'}\",str(message.value))\n",
    "        http_url = re.findall(r\"{'key': 'http\\.url', 'vStr': '(.+?)'}\",str(message.value))\n",
    "        duration = re.findall(r\"(.+?)s\",str(message.value['duration']))\n",
    "        \n",
    "        if len(http_method) > 0:\n",
    "            http_method = http_method[0]\n",
    "        if len(http_target) > 0:\n",
    "            http_target = http_target[0]\n",
    "        if len(http_url) > 0:\n",
    "            http_url = http_url[0]\n",
    "        if len(http_status_code) > 0:\n",
    "            http_status_code = http_status_code[0]\n",
    "        if len(duration) > 0:\n",
    "            duration = duration[0]\n",
    "        \n",
    "        if http_method == 'POST':\n",
    "            if \"comment\" in http_url:\n",
    "                comment = \"\"\n",
    "                fields = message.value['logs'][0]['fields']\n",
    "                description1 = re.findall(r\"{'key': 'body', 'vStr': '(.+?)'}\",str(fields))\n",
    "                if len(description1) > 0:\n",
    "                    temp = re.findall(r'\"description\":\"(.+?)\",\"_links\":',str(description1[0]))\n",
    "                    user_id = re.findall(r'\"userId\":(.+?),\"movieId\":',str(description1[0]))\n",
    "                    movie_id = re.findall(r'\"movieId\":(.+?),\"description\":',str(description1[0]))\n",
    "                    \n",
    "                    if len(temp) > 0:\n",
    "                        comment = temp[0]\n",
    "                        user_id = user_id[0]\n",
    "                        movie_id = movie_id[0]\n",
    "                \n",
    "                \n",
    "                data = [duration,comment]\n",
    "\n",
    "\n",
    "                # PREDICTION\n",
    "\n",
    "                duration = data[0]\n",
    "                comment_orig = data[1]\n",
    "\n",
    "\n",
    "                # Substituting multiple spaces with single space\n",
    "                comment = re.sub(r'\\s+', ' ', comment_orig, flags=re.I)\n",
    "\n",
    "                # Converting to Lowercase\n",
    "                comment = comment.lower()\n",
    "\n",
    "                # Lemmatization\n",
    "                comment = comment.split()\n",
    "                comment = [stemmer.lemmatize(word) for word in comment]\n",
    "                comment = ' '.join(comment)\n",
    "\n",
    "                comment_features = tfidfconverter.transform([comment]).toarray()\n",
    "\n",
    "                A = np.array([duration], dtype=float)[:,None]\n",
    "                data = np.concatenate((A, comment_features), axis=1)\n",
    "                ##### data_pred = classifier.predict(data)\n",
    "\n",
    "                date = datetime.now().strftime('%Y-%m-%d')\n",
    "                time = datetime.now().strftime('%H:%M:%S')\n",
    "                \n",
    "                numpyData = {\"array\": data,\"comment_date\": date,'comment':comment,'spanId':message.value['spanId'],'userId':user_id,'movieId':movie_id}\n",
    "                producer.send('data_to_predict_logistic_regression',numpyData)\n",
    "                \n",
    "                ##### print(counter, date, time, duration, comment_orig, data_pred[0])\n",
    "\n",
    "                ##### log_prediction = [date,time,duration,comment_orig,data_pred[0]]\n",
    "                # write a row to the csv file\n",
    "                ##### writer.writerow(log_prediction)\n",
    "                counter = counter + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb0105-ec69-4a5e-99b5-cf7a7062e2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
