{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_log_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vmadmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vmadmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vmadmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "# from xml.dom import minidom\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = []\n",
    "malicious = []\n",
    "for i in range(len(df['comment'])):\n",
    "    if df['Anomalous'][i] == 1:\n",
    "        malicious.append(df['comment'][i])\n",
    "    else:\n",
    "        normal.append(df['comment'][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_sentence=[]\n",
    "for i in normal:\n",
    "    sentences=i.split('.')\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        benign_sentence.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def fun_remove_stop_words(posts):\n",
    "\n",
    "    filtered=''\n",
    "    \n",
    "    for x in posts.split(' '):\n",
    "        if x not in stop_words:\n",
    "            filtered+=' '+x\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_text = normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from list to string\n",
    "\n",
    "data=''\n",
    "for x in plain_text:\n",
    "    data+=\" \" + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=fun_remove_stop_words(data)  # remove stop words\n",
    "data=data.split('.')              # split sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# seperate words inside tags\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i]=data[i].replace('<', ' <')\n",
    "    data[i]=data[i].replace('>', '> ')\n",
    "    data[i]=data[i].replace('=', ' = ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign records: 10356\n"
     ]
    }
   ],
   "source": [
    "print(\"Benign records: %2i\" %len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in data:\n",
    "    if val == \"\":\n",
    "        data.remove(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner_data = []\n",
    "for valu in data:\n",
    "    cleaner_data.append(valu.replace(\"<br />  <br />\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = []\n",
    "for valu in cleaner_data:\n",
    "    cleaned_data.append(valu.replace(\"\\\\\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_normal = cleaned_data[:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_values=[]\n",
    "for i in final_normal:\n",
    "    final_values.append((i,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# give labels to sql data\n",
    "\n",
    "\n",
    "for i in malicious:\n",
    "    final_values.append((i,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(final_values,columns=['comment','anomolous'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sqli.csv', index=False, encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('sqli.csv',encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization of data\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer( min_df=2, max_df=0.7, max_features=1444, stop_words=stopwords.words('english'))\n",
    "posts = vectorizer.fit_transform(df['comment'].values.astype('U')).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer_cnn_without_duration', 'wb') as fin:\n",
    "    pickle.dump(vectorizer, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1444)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.shape=(1000,38,38,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['anomolous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 38, 38, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=X_train.copy()\n",
    "trainX.shape=(X_train.shape[0],trainX.shape[1]*trainX.shape[2])\n",
    "testX=X_test.copy()\n",
    "testX.shape=(testX.shape[0],testX.shape[1]*testX.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(trainX, y_train)\n",
    "\n",
    "pred_gnb = gnb.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gnb_model_without_duration' , \"wb\") as f:\n",
    "     pickle.dump(gnb, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_gnb)):\n",
    "    if pred_gnb[i]>0.5:\n",
    "        pred_gnb[i]=1\n",
    "    elif pred_gnb[i]<=0.5:\n",
    "        pred_gnb[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(tp,tn,fp,fn):\n",
    "    \n",
    "    accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_function(tp,fp):\n",
    "    \n",
    "    precision = tp / (tp+fp)\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_function(tp,fn):\n",
    "    \n",
    "    recall=tp / (tp+fn)\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(truth,predicted):\n",
    "    \n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for true,pred in zip(truth,predicted):\n",
    "        \n",
    "        if true == 1:\n",
    "            if pred == true:\n",
    "                true_positive += 1\n",
    "            elif pred != true:\n",
    "                false_negative += 1\n",
    "\n",
    "        elif true == 0:\n",
    "            if pred == true:\n",
    "                true_negative += 1\n",
    "            elif pred != true:\n",
    "                false_positive += 1\n",
    "            \n",
    "    accuracy=accuracy_function(true_positive, true_negative, false_positive, false_negative)\n",
    "    precision=precision_function(true_positive, false_positive)\n",
    "    recall=recall_function(true_positive, false_negative)\n",
    "    \n",
    "    return (accuracy,\n",
    "            precision,\n",
    "           recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy,precision,recall=confusion_matrix(y_test,pred_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9772727272727273"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347826086956522"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, input_shape=(38,38,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128,(3,3), activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256,(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 36, 36, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,000,961\n",
      "Trainable params: 1,000,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 7s 9ms/sample - loss: 0.6043 - acc: 0.7200 - val_loss: 0.4953 - val_acc: 0.7800\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.4654 - acc: 0.8050 - val_loss: 0.4450 - val_acc: 0.7800\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.3829 - acc: 0.8438 - val_loss: 0.3419 - val_acc: 0.8700\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.2978 - acc: 0.8963 - val_loss: 0.2850 - val_acc: 0.8950\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.2132 - acc: 0.9187 - val_loss: 0.2159 - val_acc: 0.9150\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.1378 - acc: 0.9475 - val_loss: 0.1524 - val_acc: 0.9550\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.0770 - acc: 0.9825 - val_loss: 0.1047 - val_acc: 0.9750\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 6s 8ms/sample - loss: 0.0412 - acc: 0.9900 - val_loss: 0.0941 - val_acc: 0.9800\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.0261 - acc: 0.9912 - val_loss: 0.0994 - val_acc: 0.9800\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 0.0204 - acc: 0.9962 - val_loss: 0.1054 - val_acc: 0.9650\n"
     ]
    }
   ],
   "source": [
    "classifier_nn = model.fit(X_train,y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred)):\n",
    "    if pred[i]>0.5:\n",
    "        pred[i]=1\n",
    "    elif pred[i]<=0.5:\n",
    "        pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy,precision,recall=confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8936170212765957"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_model_without_duration.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_malicious(val):\n",
    "    \n",
    "    def clean_data(val):\n",
    "        val=val.replace('\\n', '')\n",
    "        val=val.replace('%20', ' ')\n",
    "        val=val.replace('=', ' = ')\n",
    "        val=val.replace('((', ' (( ')\n",
    "        val=val.replace('))', ' )) ')\n",
    "        val=val.replace('(', ' ( ')\n",
    "        val=val.replace(')', ' ) ')\n",
    "        val=val.replace('1 ', 'numeric')\n",
    "        val=val.replace(' 1', 'numeric')\n",
    "        val=val.replace(\"'1 \", \"'numeric \")\n",
    "        val=val.replace(\" 1'\", \" numeric'\")\n",
    "        val=val.replace('1,', 'numeric,')\n",
    "        val=val.replace(\" 2 \", \" numeric \")\n",
    "        val=val.replace(' 3 ', ' numeric ')\n",
    "        val=val.replace(' 3--', ' numeric--')\n",
    "        val=val.replace(\" 4 \", ' numeric ')\n",
    "        val=val.replace(\" 5 \", ' numeric ')\n",
    "        val=val.replace(' 6 ', ' numeric ')\n",
    "        val=val.replace(\" 7 \", ' numeric ')\n",
    "        val=val.replace(\" 8 \", ' numeric ')\n",
    "        val=val.replace('1234', ' numeric ')\n",
    "        val=val.replace(\"22\", ' numeric ')\n",
    "        val=val.replace(\" 8 \", ' numeric ')\n",
    "        val=val.replace(\" 200 \", ' numeric ')\n",
    "        val=val.replace(\"23 \", ' numeric ')\n",
    "        val=val.replace('\"1', '\"numeric')\n",
    "        val=val.replace('1\"', '\"numeric')\n",
    "        val=val.replace(\"7659\", 'numeric')\n",
    "        val=val.replace(\" 37 \", ' numeric ')\n",
    "        val=val.replace(\" 45 \", ' numeric ')\n",
    "        \n",
    "        return val\n",
    "    \n",
    "    val=clean_data(val)\n",
    "    val=[val]\n",
    "    val=vectorizer.transform(val).toarray()\n",
    "    result=gnb.predict(val)\n",
    "    \n",
    "    if result>0.5:\n",
    "        print(\"ALERT :::: This can be SQL injection\")\n",
    "    elif result<=0.5:\n",
    "        print(\"It seems to be safe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"./data_comments/original_datasets/sqli.csv\", encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comments = df_full['Sentence'][101:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comm in test_comments:\n",
    "    detect_malicious(comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=''' )  union select * from information_schema.tables'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_val=clean_data(c1)\n",
    "input_val=[input_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_val=vectorizer.transform(input_val).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=gnb.predict(input_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result>0.5:\n",
    "    print(\"ALERT :::: This can be SQL injection\")\n",
    "elif result<=0.5:\n",
    "    print(\"It seems to be safe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = ['This is nice movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_val=clean_data(comms_vectorized)\n",
    "input_val=[input_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comms_vectorized = vectorizer.transform(comm).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comms_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=gnb.predict(comms_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result>0.5:\n",
    "    print(\"ALERT :::: This can be SQL injection\")\n",
    "elif result<=0.5:\n",
    "    print(\"It seems to be safe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = r\" AND 1 = utl_inaddr.get_host_address  (  (  SELECT DISTINCT ( USERNAME )  FROM  ( SELECT DISTINCT ( USERNAME ) , ROWNUM AS LIMIT FROM SYS.ALL_USERS )  WHERE LIMIT = 1  )  )   AND 'i' = 'i'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_val=clean_data(c2)\n",
    "input_val=[input_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_val=vectorizer.transform(input_val).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=gnb.predict(input_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result>0.5:\n",
    "    print(\"ALERT :::: This can be SQL injection\")\n",
    "elif result<=0.5:\n",
    "    print(\"It seems to be safe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "gnb.save('gnb_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "mymodel = load_model('my_model.h5')\n",
    "myvectorizer = pickle.load(open(\"vectorizer\", 'rb'))\n",
    "\n",
    "\n",
    "def predict_sqli_attack():\n",
    "\t\n",
    "\tbeautify=''\n",
    "\tfor i in range(20):\n",
    "        beautify+= \"=\"\n",
    "\n",
    "\tprint(beautify) \n",
    "\tinput_val=input(\"Give me some data to work on : \")\n",
    "\tprint(beautify)\n",
    "\n",
    "\tdef clean_data(input_val):    \n",
    "\n",
    "\t    input_val=input_val.replace('\\n', '')\n",
    "\t    input_val=input_val.replace('%20', ' ')\n",
    "\t    input_val=input_val.replace('=', ' = ')\n",
    "\t    input_val=input_val.replace('((', ' (( ')\n",
    "\t    input_val=input_val.replace('))', ' )) ')\n",
    "\t    input_val=input_val.replace('(', ' ( ')\n",
    "\t    input_val=input_val.replace(')', ' ) ')\n",
    "\t    input_val=input_val.replace('1 ', 'numeric')\n",
    "\t    input_val=input_val.replace(' 1', 'numeric')\n",
    "\t    input_val=input_val.replace(\"'1 \", \"'numeric \")\n",
    "\t    input_val=input_val.replace(\" 1'\", \" numeric'\")\n",
    "\t    input_val=input_val.replace('1,', 'numeric,')\n",
    "\t    input_val=input_val.replace(\" 2 \", \" numeric \")\n",
    "\t    input_val=input_val.replace(' 3 ', ' numeric ')\n",
    "\t    input_val=input_val.replace(' 3--', ' numeric--')\n",
    "\t    input_val=input_val.replace(\" 4 \", ' numeric ')\n",
    "\t    input_val=input_val.replace(\" 5 \", ' numeric ')\n",
    "\t    input_val=input_val.replace(' 6 ', ' numeric ')\n",
    "\t    input_val=input_val.replace(\" 7 \", ' numeric ')\n",
    "\t    input_val=input_val.replace(\" 8 \", ' numeric ')\n",
    "\t    input_val=input_val.replace('1234', ' numeric ')\n",
    "\t    input_val=input_val.replace(\"22\", ' numeric ')\n",
    "\t    input_val=input_val.replace(\" 8 \", ' numeric ')\n",
    "\t    input_val=input_val.replace(\" 200 \", ' numeric ')\n",
    "\t    input_val=input_val.replace(\"23 \", ' numeric ')\n",
    "\t    input_val=input_val.replace('\"1', '\"numeric')\n",
    "\t    input_val=input_val.replace('1\"', '\"numeric')\n",
    "\t    input_val=input_val.replace(\"7659\", 'numeric')\n",
    "\t    input_val=input_val.replace(\" 37 \", ' numeric ')\n",
    "\t    input_val=input_val.replace(\" 45 \", ' numeric ')\n",
    "\t    \n",
    "\t    return input_val\n",
    "\n",
    "\tinput_val=clean_data(input_val)\n",
    "\tinput_val=[input_val]\n",
    "\n",
    "\n",
    "\n",
    "\tinput_val=myvectorizer.transform(input_val).toarray()\n",
    "\n",
    "\tresult=mymodel.predict(input_val)\n",
    "\n",
    "\n",
    "\tprint(beautify)\n",
    "\tif result>0.5:\n",
    "\t\tprint(\"ALERT :::: This can be SQL injection\")\n",
    "\telif result<=0.5:\n",
    "\t\tprint(\"It seems to be safe\")\n",
    "\n",
    "\tprint(beautify)\n",
    "\n",
    "\n",
    "predict_sqli_attack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
